{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aee90d1",
   "metadata": {},
   "source": [
    "# Fourth Session of Stochastic Modelling\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guglielmopadula/StochasticModelling2022-2023/blob/main/FourthSession.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7545a8f",
   "metadata": {},
   "source": [
    "### A very fast recap on Discrete Time Markov Chain\n",
    "A stochastic process $X_{t}$ satisfies the **Markov Property** if $$P(X_{t}|\\{X_{k}| k<s\\})=P(X_{t}|X_{s}) \\quad \\forall s<t$$.\n",
    "If the state space of $X_{t}$ $S$ is finite and $t$ is discrete (let's call it $n$) then we have a **Discrete Time Markov Chain**.\n",
    "Because of the Markov property and the bayes theorem we have $$P(X_{n}=j)=\\sum_{i=1}^{|S|} P(X_{n}=j|X_{n-1}=i)P(X_{n-1}=j)=\\sum_{i=1}^{S}a_{ij}(n)P(X_{n-1}=j)$$ so $$P(X_{n})=A(n)P(X_{n-1})$$.\n",
    "If $A(n)$ does not depend on $n$, the DTMC is **time homogeneous**.\n",
    "\n",
    "Let's try to study the convergence properties of the probability of an homogenous DTMC.\n",
    "If $A$ is a DTMC matrix the $A\\cdot 1=1$ so $1$ is a right eigenvector and $A$ has an eigenvalue $\\lambda=1$ so it has also a right eigenvector $p$ such that $pA=p$. It can be further proven that $p\\ge 0$ and $|p|_{1}=1$ so $p$ is an equilibrium probability. \n",
    "In general nothing can be said about convergence and uniqueness of the probability $p$ of equilibrium.\n",
    "Before going depth in this problem, let's start talking about Discrete Time Markov chain simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba48ca7",
   "metadata": {},
   "source": [
    "### Simulation of a DTMC and convergence of the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def DtmcSimulation(A,p0,n):\n",
    "    if not np.prod(A>=0):\n",
    "        raise Exception(\"Elements are not non negative\")\n",
    "    if not np.prod(np.isclose(np.sum(A,axis=1),np.ones(A.shape[0]))):\n",
    "        raise Exception(\"at least one row does not sum up to 1\")\n",
    "    if not np.isclose(np.sum(p0),1):\n",
    "        raise Exception(\"initial probability does not sum up to 1\")\n",
    "\n",
    "    l=[]\n",
    "    x0=np.random.choice(np.arange(p0.shape[0]),size=1,p=p0)\n",
    "    l.append(x0)\n",
    "    x=x0\n",
    "    for i in range(1,n):\n",
    "        p=A[x].reshape(-1)\n",
    "        x=np.random.choice(np.arange(p.shape[0]),size=1,p=p)\n",
    "        l.append(x)\n",
    "    return l,A,p0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbcadd2",
   "metadata": {},
   "source": [
    "Let's try to use bad behaved matrices and vector and see if an exception is thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6cbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.random.rand(4,4)\n",
    "p=np.random.rand(4)\n",
    "print(p.shape[0])\n",
    "DtmcSimulation(A,p,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9039f5c",
   "metadata": {},
   "source": [
    "It woorks!!!\n",
    "\n",
    "Let's suppose we just arrived at the Deus (a Trieste Disco Club), our situation can be described by the following three states:\n",
    "1) Taking something at the Bar\n",
    "2) Dancing\n",
    "3) Taking our things and going home\n",
    "\n",
    "Let's assume our markov chain is homogeneous. State 3 is absorbing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#0: Bar\n",
    "#1: Dancing\n",
    "#2: Home\n",
    "def DEUS_Simulation(n):\n",
    "    A=np.array([[0.4,0.5,0.1],[0.5,0.4,0.1],[0,0,1]])\n",
    "    p0=np.array([0.5,0.5,0])\n",
    "    return DtmcSimulation(A,p0,n)\n",
    "\n",
    "n=100\n",
    "samples,A,p0=DEUS_Simulation(n)\n",
    "print(samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4aed3a",
   "metadata": {},
   "source": [
    "**In general a trajectory of a DTMC will converge if and only if there is a least an absorbing state**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9738e3",
   "metadata": {},
   "source": [
    "### Convergence of the steady state probability\n",
    "\n",
    "\n",
    "We will know develop a machinery to understand the number of  steady state equilibrium probabilities.\n",
    "\n",
    "Because every DTMC has a steady state solution it has at least an eigenvalues such that $||\\lambda||=1$, so we can't use the theorem that we saw on the previous lab.\n",
    "Howewer there are other useful properties:\n",
    "- it can be proven that all the spectre $\\Lambda(A)\\subseteq \\{\\lambda \\in \\mathbb{C} \\quad s.t \\quad ||\\lambda||_{2}\\le 1\\}$. Remember that ($||\\alpha+i\\beta||_{2}=\\sqrt{\\alpha^2+\\beta^2}$)\n",
    "- it can be proven that eigenvalues $\\lambda$ such that $||\\lambda||_{2}=1$ have the same algebraic and geometry multiplicity \n",
    "We are going to use the Jordan Decomposition, which is says that a general matrix $A$ can be decomposed as $$A=SJS^{-1}$$ where $J$ is of type:\n",
    "\n",
    "$$\\left(\\begin{array}{lll|ll|l|l}\n",
    "\\lambda_{1} & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & \\lambda_{1} & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & \\lambda_{1} & 0 & 0 & 0 & 0 \\\\\n",
    "\\hline\n",
    " 0 & 0 & 0 & \\lambda_{2} & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & \\lambda_{2} & 0 & 0 \\\\\n",
    "\\hline\n",
    "0 & 0 & 0 & 0 & 0 & \\lambda_{3}& 0 \\\\\n",
    " \\hline\n",
    "0 & 0 & 0 & 0 & 0 & 0 & \\lambda_{4}\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "So if we do $Y_{t}=X_{t}S$ we get a system which is decomposable in blocks of two types.\n",
    "- block of type $$Y_{n+1}=Y_{n}\\left(\\begin{array}{lll} \\lambda & 1 & 0 \\\\ 0 &\\lambda & 1 \\\\ 0 & 0 & \\lambda \\end{array}\\right)$$ in which the geometric and algebraic multiplicity differ. Notice that because of the property 2 and 1 we must have $||\\lambda||<1$, so by the last lab theorem we have that this system block converges to $0$.\n",
    "- block of type $y_{n+1}=\\lambda y_{n}$. Because of property one we have $||\\lambda||\\le 1$.\n",
    "  - if $||\\lambda||<1$ it converges to $0$ because of the last lab theorem\n",
    "  - if $||\\lambda||=1$ we can't apply last lab theorem. However in this case $$\\lambda=\\cos(\\theta)+i\\sin(\\theta)$$ for $\\theta \\in [0,2\\pi]$ so $$\\lambda^{k}=\\cos(k\\theta)+i\\sin(k\\theta)$$ which converges if and only if $\\theta=0$ so\n",
    "    -  if $\\theta=0$ and so $\\lambda=1$ the point is an equilibrium point and the block converges\n",
    "    -  if $\\theta\\neq 0$ and so $\\lambda\\neq 1$ and the block does not converge\n",
    "\n",
    "With this observation we can formulate our machinery:\n",
    "- compute the eigenvalues of the stochastic matrix\n",
    "- use the following table\n",
    "\n",
    "$$\\begin{array}{ |c|c|c| } \n",
    " \\hline\n",
    "  & \\{i \\text{ s.t } \\lambda_{i}\\neq 1 \\wedge ||\\lambda_{i}||_{2}=1  \\}|=0 & \\{i \\text{ s.t } \\lambda_{i}\\neq 1 \\wedge ||\\lambda_{i}||_{2}=1  \\}|>0 \\\\\n",
    " \\hline\n",
    " |\\{i \\text{ s.t } \\lambda_{i}=1 \\}|=1 & \\text{Unique steady state (with convergence)} & \\text{Unique steady state (no convergence)} \\\\\n",
    " \\hline\n",
    " |\\{i \\text{ s.t } \\lambda_{i}=1 \\}|>1 & \\text{Infinite number of steady states (with convergence)} & \\text{Infinite number of steady states (no convergence)} \\\\ \n",
    " \\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fd9af",
   "metadata": {},
   "source": [
    "Let's now check the convergence of our matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convergence(A,eps):\n",
    "    eigens=np.linalg.eigvals(A)\n",
    "    eigens=eigens[np.abs(np.abs(eigens)-1)<eps] ##exctract eigenvalues of the unit circle\n",
    "    equal_ones=eigens[np.logical_and(eigens>0,np.abs(np.imag(eigens))<eps)]\n",
    "    if len(equal_ones)<len(eigens):\n",
    "        print(\"no steady state distribution\")\n",
    "    else:\n",
    "        if len(equal_ones)==1:\n",
    "            print(\"one unique steady state distribution\")\n",
    "        else:\n",
    "            print(\"infinite number of steady states\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "check_convergence(A,0.01)\n",
    "plt.plot(np.arange(len(samples)),np.array(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68642f5",
   "metadata": {},
   "source": [
    "Let's now write a general code for computing steady state probability and apply it to our DEUS simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steadystate_probability(A,p0,n):\n",
    "    p=p0\n",
    "    l=[]\n",
    "    for i in range(n):\n",
    "        p=p@A\n",
    "        l.append(p)\n",
    "    return l\n",
    "\n",
    "check_convergence(A,0.001)\n",
    "prob=steadystate_probability(A,p0,n)\n",
    "plt.plot(np.arange(len(prob)),np.array(prob),label=[\"state 1\",\"state 2\",\"state 3\"])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36998891",
   "metadata": {},
   "source": [
    "Example A:\n",
    "$$\\left(\\begin{array}{cccc}\n",
    "0.1 & 0.1 & 0.1 & 0.7 \\\\\n",
    "0.25 & 0.25 & 0.25 & 0.25 \\\\\n",
    "0.3 & 0.3 & 0.2 & 0.2 \\\\\n",
    "0.4 & 0.2 & 0.3 & 0.1\n",
    "\\end{array}\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=30\n",
    "A=np.array([[0.1,0.1,0.1,0.7],\n",
    "   [0.25,0.25,0.25,0.25],\n",
    "   [0.3,0.3,0.2,0.2],\n",
    "  [0.4,0.2,0.3,0.1]])\n",
    "p0=np.random.rand(4)\n",
    "p0=p0/np.sum(p0)\n",
    "\n",
    "check_convergence(A,0.001)\n",
    "prob=steadystate_probability(A,p0,n)\n",
    "plt.plot(np.arange(len(prob)),np.array(prob),label=[\"state 1\",\"state 2\",\"state 3\",\"state 4\"])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory,_,_=DtmcSimulation(A,p0,n)\n",
    "plt.plot(np.arange(len(trajectory)),np.array(trajectory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54751b82",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6046b",
   "metadata": {},
   "source": [
    "Example B:\n",
    "$$\\left(\\begin{array}{cccc}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 0.5 & 0.2 & 0.3 \\\\\n",
    "0 & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\\\\n",
    "0 & \\frac{2}{3} & \\frac{1}{3} & 0\n",
    "\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[1,0,0,0],\n",
    "   [0,0.5,0.2,0.3],\n",
    "   [0,1/3,1/3,1/3],\n",
    "  [0,2/3,1/3,0]])\n",
    "\n",
    "check_convergence(A,0.001)\n",
    "prob=steadystate_probability(A,p0,n)\n",
    "plt.plot(np.arange(len(prob)),np.array(prob),label=[\"state 1\",\"state 2\",\"state 3\",\"state 4\"])\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c629c5",
   "metadata": {},
   "source": [
    "Let's now try a new starting probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=np.array([1,0,0,0])\n",
    "prob=steadystate_probability(A,p1,n)\n",
    "plt.plot(np.arange(len(prob)),np.array(prob),label=[\"state 1\",\"state 2\",\"state 3\",\"state 4\"])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457de1d1",
   "metadata": {},
   "source": [
    "And now let's try a combination of the previous two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b539f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=0.5*p0+0.5*p1\n",
    "print(p2)\n",
    "prob=steadystate_probability(A,p2,n)\n",
    "plt.plot(np.arange(len(prob)),np.array(prob),label=[\"state 1\",\"state 2\",\"state 3\",\"state 4\"])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0975ef",
   "metadata": {},
   "source": [
    "With different combination you can obtain infinite steady state distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49377bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory,_,_=DtmcSimulation(A,p0,n)\n",
    "plt.plot(np.arange(len(trajectory)),np.array(trajectory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700d0f8",
   "metadata": {},
   "source": [
    "Example C:\n",
    "$$\\left(\\begin{array}{cccc}\n",
    "0 & 0.5 & 0 & 0.5 \\\\\n",
    "0.75 & 0 & 0.25 & 0 \\\\\n",
    "0 & 0.75 & 0 & 0.25 \\\\\n",
    "0.75 & 0 & 0.25 & 0\n",
    "\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[0,0.5,0,0.5],\n",
    "   [0.75,0,0.25,0],\n",
    "   [0,0.75,0,0.25],\n",
    "  [0.75,0,0.25,0]])\n",
    "check_convergence(A,0.001)\n",
    "\n",
    "prob=steadystate_probability(A,p0,n)\n",
    "plt.plot(np.arange(len(prob)),np.array(prob),label=[\"state 1\",\"state 2\",\"state 3\",\"state 4\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory,_,_=DtmcSimulation(A,p0,n)\n",
    "plt.plot(np.arange(len(trajectory)),np.array(trajectory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4428534",
   "metadata": {},
   "source": [
    "Let's try to assess the relation between trajectiory convergence and probability convergence. We have seen that:\n",
    "- in the DEUX example both trajectory and probability converge\n",
    "- in example A and B the probability converge but not the trajectory\n",
    "- in example C neither the trajectory neither the probability converge\n",
    "\n",
    "If every possible trajectory converges, then it means that it converges to a absorbing state, so it means that the markov chain is absorbing and so that the chain admits a steady state probability. So it is not possible to have a DTMC such that the trajectory converges and the probability does not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
